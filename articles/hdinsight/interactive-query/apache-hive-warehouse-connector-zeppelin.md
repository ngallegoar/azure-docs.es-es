---
title: 'Hive Warehouse Connector - Apache Zeppelin con Livy: Azure HDInsight'
description: Obtenga información sobre cómo integrar Hive Warehouse Connector con Apache Zeppelin en Azure HDInsight.
author: nis-goel
ms.author: nisgoel
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 05/22/2020
ms.openlocfilehash: 1f9d2d9bd2a58fa4c6f14db8ffd067bb39fc1553
ms.sourcegitcommit: 1f25aa993c38b37472cf8a0359bc6f0bf97b6784
ms.translationtype: HT
ms.contentlocale: es-ES
ms.lasthandoff: 05/26/2020
ms.locfileid: "83853717"
---
# <a name="integrate-apache-zeppelin-with-hive-warehouse-connector-in-azure-hdinsight"></a>Integración de Apache Zeppelin con Hive Warehouse Connector en Azure HDInsight

Los clústeres de HDInsight Spark incluyen cuadernos de Apache Zeppelin con distintos intérpretes. Este artículo se centrará solo en el intérprete Livy para acceder a tablas de Hive desde Spark mediante Hive Warehouse Connector.

## <a name="prerequisite"></a>Requisito previo

Complete los pasos de [configuración de Hive Warehouse Connector](apache-hive-warehouse-connector.md#hive-warehouse-connector-setup).

## <a name="getting-started"></a>Introducción

1. Use el [comando ssh](../hdinsight-hadoop-linux-use-ssh-unix.md) para conectarse al clúster de Apache Spark. Modifique el comando siguiente: reemplace CLUSTERNAME por el nombre del clúster y, luego, escriba el comando:

    ```cmd
    ssh sshuser@CLUSTERNAME-ssh.azurehdinsight.net
    ```

1. Desde la sesión de ssh, ejecute el comando siguiente para anotar las versiones de `hive-warehouse-connector-assembly` y `pyspark_hwc`:

    ```bash
    ls /usr/hdp/current/hive_warehouse_connector
    ```

    Guarde la salida para usarla después al configurar Apache Zeppelin.

## <a name="configure-livy"></a>Configuración de Livy

Se requieren las configuraciones siguientes para acceder a tablas de Hive desde Zeppelin con el intérprete de Livy.

### <a name="interactive-query-cluster"></a>Clúster de Interactive Query

1. Desde un explorador web, vaya a `https://LLAPCLUSTERNAME.azurehdinsight.net/#/main/services/HDFS/configs`, donde LLAPCLUSTERNAME es el nombre del clúster de Interactive Query.

1. Vaya a **Advanced** > **Custom core-site** (Opciones avanzadas > Sitio principal personalizado). Seleccione **Add Property...** (Agregar propiedad) para agregar las configuraciones siguientes:

    | Configuración                 | Value |
    | ----------------------------- |-------|
    | hadoop.proxyuser.livy.groups  | *     |
    | hadoop.proxyuser.livy.hosts   | *     |

1. Guarde los cambios y reinicie todos los componentes afectados.

### <a name="spark-cluster"></a>Clúster de Spark

1. En un explorador web, vaya a `https://CLUSTERNAME.azurehdinsight.net/#/main/services/SPARK2/configs`, donde CLUSTERNAME es el nombre del clúster de Apache Spark.

1. Expanda **Custom livy2-conf**. Seleccione **Add Property...** (Agregar propiedad) para agregar la configuración siguiente:

    | Configuración                 | Value                                      |
    | ----------------------------- |------------------------------------------  |
    | livy.file.local-dir-whitelist | /usr/hdp/current/hive_warehouse_connector/ |

1. Guarde los cambios y reinicie todos los componentes afectados.

### <a name="configure-livy-interpreter-in-zeppelin-ui-spark-cluster"></a>Configuración del intérprete de Livy en la interfaz de usuario de Zeppelin (clúster de Spark)

1. Desde un explorador web, vaya a `https://CLUSTERNAME.azurehdinsight.net/zeppelin/#/interpreter`, donde `CLUSTERNAME` es el nombre del clúster de Apache Spark.

1. Vaya a **livy2**.

1. Agregue las configuraciones siguientes:

    | Configuración                 | Value                                      |
    | ----------------------------- |:------------------------------------------:|
    | livy.spark.hadoop.hive.llap.daemon.service.hosts | @llap0 |
    | livy.spark.security.credentials.hiveserver2.enabled | true |
    | livy.spark.sql.hive.llap | true |
    | livy.spark.yarn.security.credentials.hiveserver2.enabled | true |
    | livy.superusers | livy,zeppelin |
    | livy.spark.jars | `file:///usr/hdp/current/hive_warehouse_connector/hive-warehouse-connector-assembly-VERSION.jar`.<br>Reemplace VERSION por el valor obtenido anteriormente en [Introducción](#getting-started). |
    | livy.spark.submit.pyFiles | `file:///usr/hdp/current/hive_warehouse_connector/pyspark_hwc-VERSION.zip`.<br>Reemplace VERSION por el valor obtenido anteriormente en [Introducción](#getting-started). |
    | livy.spark.sql.hive.hiveserver2.jdbc.url | Establézcalo en la dirección URL JDBC interactiva de HiveServer2 del clúster de Interactive Query. |
    | spark.security.credentials.hiveserver2.enabled | true |

1. Solo para clústeres de ESP, agregue la configuración siguiente:

    | Configuración| Value|
    |---|---|
    | livy.spark.sql.hive.hiveserver2.jdbc.url.principal | `hive/<headnode-FQDN>@<AAD-Domain>` |

    Reemplace `<headnode-FQDN>` por el nombre de dominio completo del nodo principal del clúster de Interactive Query.
    Reemplace `<AAD-DOMAIN>` por el nombre de la instancia de Azure Active Directory (AAD) a la que está unido el clúster. Use una cadena en mayúsculas para el valor `<AAD-DOMAIN>`; de lo contrario, la credencial no se encontrará. Consulte en `/etc/krb5.conf` los nombres de dominio kerberos si es necesario.

1. Guarde los cambios y reinicie el intérprete de Livy.

Si el intérprete de Livy no es accesible, modifique el archivo `shiro.ini` del componente Zeppelin en Ambari. Para obtener más información, vea [Configuración de la seguridad de Apache Zeppelin](https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.0.1/configuring-zeppelin-security/content/enabling_access_control_for_interpreter__configuration__and_credential_settings.html).  


## <a name="running-queries-in-zeppelin"></a>Ejecución de consultas en Zeppelin 

Inicie un cuaderno de Zeppelin con el intérprete de Livy y ejecute lo siguiente

```python
%livy2

import com.hortonworks.hwc.HiveWarehouseSession
import com.hortonworks.hwc.HiveWarehouseSession._
import org.apache.spark.sql.SaveMode

# Initialize the hive context
val hive = HiveWarehouseSession.session(spark).build()

# Create a database
hive.createDatabase("hwc_db",true)
hive.setDatabase("hwc_db")

# Create a Hive table
hive.createTable("testers").ifNotExists().column("id", "bigint").column("name", "string").create()

val dataDF = Seq( (1, "foo"), (2, "bar"), (8, "john")).toDF("id", "name")

# Validate writes to the table
dataDF.write.format("com.hortonworks.spark.sql.hive.llap.HiveWarehouseConnector").mode("append").option("table", "hwc_db.testers").save()

# Validate reads
hive.executeQuery("select * from testers").show()

```

## <a name="next-steps"></a>Pasos siguientes

* [Operaciones de HWC y Apache Spark](./apache-hive-warehouse-connector-operations.md)
* [Integración de HWC con Apache Spark y Apache Hive](./apache-hive-warehouse-connector.md)
* [Uso de Interactive Query con HDInsight](./apache-interactive-query-get-started.md)